## What is Braindler-Assistant?

Braindler-Assistant –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –º—É–ª—å—Ç–∏–∫–∞–Ω–∞–ª—å–Ω–æ–≥–æ AI-–ø–æ–º–æ—â–Ω–∏–∫–∞, –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –Ω–∞ –ø–æ–¥–¥–µ—Ä–∂–∫—É –∏ –ø—Ä–æ–¥–∞–∂–∏ —á–µ—Ä–µ–∑ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä—ã.

## üß† –ß—Ç–æ —Ç–∞–∫–æ–µ Braindler-Assistant?

**Braindler-Assistant** ‚Äî —ç—Ç–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –±–æ—Ç, —Ä–∞–±–æ—Ç–∞—é—â–∏–π –≤ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä–∞—Ö (Telegram, WhatsApp, Line, WeChat, Instagram), –∫–æ—Ç–æ—Ä—ã–π:

- –°–ª–µ–¥—É–µ—Ç –∑–∞—Ä–∞–Ω–µ–µ –∑–∞–¥–∞–Ω–Ω–æ–º—É **AI-—á–∞—Ç-—Å–∫—Ä–∏–ø—Ç—É** ‚Äî –±–ª–æ—á–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º —Å–æ–æ–±—â–µ–Ω–∏–π –∏ –≤–æ–∑–º–æ–∂–Ω—ã–º–∏ –æ—Ç–≤–µ—Ç–∞–º–∏.
- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ —Ä–∞–º–∫–∏ **AI-—á–∞—Ç-—Å–∫—Ä–∏–ø—Ç–∞**, –±–æ—Ç –ø—ã—Ç–∞–µ—Ç—Å—è **–∏–º–ø—Ä–æ–≤–∏–∑–∏—Ä–æ–≤–∞—Ç—å**
- –ü—Ä–µ–¥–ª–∞–≥–∞—é—Ç—Å—è –ø–æ–∂–µ–ª–∞–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è **AI-—á–∞—Ç-—Å–∫—Ä–∏–ø—Ç–∞** –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤.
- –ü—Ä–∏ –Ω–µ–æ—é—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –ø–µ—Ä–µ—Å—ã–ª–∞–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ç–æ—Ä—É, –ø–æ–∑–≤–æ–ª—è—è –µ–º—É –≤–º–µ—à–∏–≤–∞—Ç—å—Å—è –≤ –¥–∏–∞–ª–æ–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
- –ï—Å–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç –≤ —Ç–µ—á–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏, –∏–∏-–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç –¥–∏–∞–ª–æ–≥.
- –ó–∞–ø–æ–º–∏–Ω–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Å—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–æ–≤ —Ä–∞–∑–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤ –∏ —Å—Ç–∞—Ä–∞–µ—Ç—Å—è –Ω–µ —Å–º–µ—à–∏–≤–∞—Ç—å –∏—Ö –º–µ–∂–¥—É —Å–æ–±–æ–π.
- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –º—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ–µ –æ–±—â–µ–Ω–∏–µ, –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É—è –æ—Ç–≤–µ—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –æ–ø—ã—Ç–∞

---

## üöÄ –û—Å–Ω–æ–≤–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏

- **–ú—É–ª—å—Ç–∏–∫–∞–Ω–∞–ª—å–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞**: Telegram, WhatsApp, Line, WeChat, Instagram.
- **AI-—á–∞—Ç-—Å–∫—Ä–∏–ø—Ç—ã**: –≥–∏–±–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é –∏–º–ø—Ä–æ–≤–∏–∑–∞—Ü–∏–∏.
- **–ü–æ–ª—É–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Ä–µ–∂–∏–º**: –æ–ø–µ—Ä–∞—Ç–æ—Ä –º–æ–∂–µ—Ç –≤–º–µ—à–∏–≤–∞—Ç—å—Å—è –≤ –¥–∏–∞–ª–æ–≥ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
- **–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–ø—ã—Ç–µ**: –±–æ—Ç –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–∏–∞–ª–æ–≥–æ–≤.
- **–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç–∏–ª–∏ –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤**: –±–æ—Ç –∑–∞–ø–æ–º–∏–Ω–∞–µ—Ç –∏ —Ä–∞–∑–ª–∏—á–∞–µ—Ç —Å—Ç–∏–ª–∏ –æ–±—â–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ç–æ—Ä–æ–≤.
- **–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–æ—Å—Ç—å**: –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –æ–±—â–µ–Ω–∏—è –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —è–∑—ã–∫–∞—Ö —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –∫–æ—Ä—Ä–µ–∫—Ü–∏–µ–π. 
---

## üß© –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ

- **–ü–æ–¥–¥–µ—Ä–∂–∫–∞ –∫–ª–∏–µ–Ω—Ç–æ–≤**: –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ —á–∞—Å—Ç–æ –∑–∞–¥–∞–≤–∞–µ–º—ã–µ –≤–æ–ø—Ä–æ—Å—ã.
- **–ü—Ä–æ–¥–∞–∂–∏**: –≤–µ–¥–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–æ–≤ —Å –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º–∏ –∫–ª–∏–µ–Ω—Ç–∞–º–∏ –∏ —Å–æ–ø—Ä–æ–≤–æ–∂–¥–µ–Ω–∏–µ —Å–¥–µ–ª–æ–∫.
- **–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥**: –ø—Ä–æ–≤–µ–¥–µ–Ω–∏–µ –æ–ø—Ä–æ—Å–æ–≤, —Ä–∞—Å—Å—ã–ª–æ–∫ –∏ –∞–∫—Ü–∏–π —á–µ—Ä–µ–∑ –º–µ—Å—Å–µ–Ω–¥–∂–µ—Ä—ã –ø–æ –∫–ª–∏–µ–Ω—Ç—Å–∫–æ–π –±–∞–∑–µ —Å —Å–æ–≥–ª–∞—Å–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
- **–û–±—Ä–∞—Ç–Ω–∞—è —Å–≤—è–∑—å**: —Å–±–æ—Ä –æ—Ç–∑—ã–≤–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π.

---

## üîß –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏

-
- **–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏**: Telegram API, WhatsApp Business API, Line Messaging API –∏ –¥—Ä—É–≥–∏–µ.


Braindler-Assistant ‚Äî —ç—Ç–æ –º–æ—â–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –æ–±—â–µ–Ω–∏—è —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏, —Å–æ—á–µ—Ç–∞—é—â–∏–π –≤ —Å–µ–±–µ –≥–∏–±–∫–æ—Å—Ç—å AI –∏ –∫–æ–Ω—Ç—Ä–æ–ª—å –æ–ø–µ—Ä–∞—Ç–æ—Ä–∞.

# üß† Braindler LLM-RAG Core

**Braindler-llm-rag** is the core engine behind the Braindler intelligent assistant platform, combining the power of a Large Language Model (LLM) with Retrieval-Augmented Generation (RAG) techniques.  
The project provides a universal backend for retrieving knowledge from user data and generating precise, factual responses.

---

## üìö Project Overview

Braindler-llm-rag enables:
- Indexing user documents into a vector database.
- Retrieving relevant knowledge fragments in response to user queries.
- Building a context prompt for the LLM based on retrieved data.
- Generating accurate, fact-based answers using private information.

The system is designed for **data privacy**, **scalability**, and **easy integration** with various clients (such as Telegram bots, web apps, etc.).

---

## üèõÔ∏è Architecture

The Braindler-llm-rag architecture consists of the following core components:

### 1. **User Query**  
The user sends a query via an external client (e.g., bot, web interface, API gateway).

### 2. **Preprocessing**  
The backend:
- Normalizes the text.
- Detects the query language.
- Prepares the query for retrieval.

### 3. **RAG Pipeline**

**Retrieval:**
- The query is embedded into a vector using an embedding model.
- A vector search is performed against the vector database (e.g., FAISS, Milvus, Pinecone).
- The top-N most relevant document fragments are retrieved.

**Augmentation:**
- Retrieved fragments are assembled into a context.
- The user query + context are combined into a structured prompt for the LLM.

### 4. **Generation**
- The prompt is sent to the LLM (e.g., Llama 3.1 hosted locally or via API).
- The LLM generates a natural language response based on the provided context.

### 5. **Postprocessing**
- The response is cleaned, formatted, and prepared for delivery.
- The answer is sent back to the client (bot, frontend, API).

---

## üî• Key Technical Components

| Component | Description |
|:----------|:------------|
| **Backend** | FastAPI server implementing the RAG pipeline and exposing public/private APIs. |
| **Embedding Model** | Sentence-Transformer (e.g., `all-MiniLM-L6-v2`) or a domain-specific multilingual model. |
| **Vector Store** | FAISS (local) or Milvus/Pinecone (cloud) for vector search and knowledge retrieval. |
| **LLM Core** | Llama 3.1 model deployed locally on GPU, accessed via HuggingFace or llama.cpp server. |
| **Monitoring** | Prometheus/Grafana stack to monitor system metrics and performance KPIs. |

---

## üöÄ Quick Start

```bash
git clone https://github.com/braindler/braindler-llm-rag.git
cd braindler-llm-rag
```

Install dependencies:
```bash
pip install -r requirements.txt
```

Index documents into the knowledge base:
```bash
python scripts/index_documents.py --path ./knowledge_base/
```

Run the backend server:
```bash
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

Start the LLM inference server separately (if needed):
```bash
python scripts/run_llm_server.py
```

---

## ‚öôÔ∏è Main API Endpoints

| Method | URL | Description |
|:------|:----|:------------|
| `POST` | `/query` | Send a user question and receive a generated response. |
| `POST` | `/upload` | Upload new documents to index into the knowledge base. |
| `GET` | `/health` | Health check of the service. |

---

## üß© Configuration (.env Example)

```env
VECTOR_DB_TYPE=faiss
VECTOR_DB_PATH=./vector_store
EMBEDDING_MODEL=all-MiniLM-L6-v2
LLM_API_URL=http://localhost:5000/generate
TOP_K_DOCUMENTS=5
PROMPT_TEMPLATE_PATH=./prompts/default.txt
```

---

## üìà Monitoring and Metrics

Braindler-llm-rag exports Prometheus metrics:
- `request_processing_time_seconds`
- `vector_search_time_seconds`
- `llm_inference_time_seconds`
- `query_success_rate`

A pre-built Grafana dashboard is available for quick setup.

---

## ‚ö° Usage Examples

Example query:
```bash
curl -X POST http://localhost:8000/query \
-H "Content-Type: application/json" \
-d '{"question": "What is the duration of the lease agreement?"}'
```

Example response:
```json
{
  "answer": "The lease agreement is valid for 11 months with the possibility of extension."
}
```

---

## üìú License

The project is distributed under the MIT License.  
We welcome contributions via Pull Requests and Issue reports!

---

# üöÄ Join the Braindler Journey!

Braindler-llm-rag powers intelligent systems where your data stays private, and knowledge is always within reach.
